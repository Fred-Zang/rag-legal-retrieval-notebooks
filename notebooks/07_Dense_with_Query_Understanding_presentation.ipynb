{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc28a2c",
   "metadata": {},
   "source": [
    "# üß† Script 07 ‚Äî Dense Retrieval + Query Understanding\n",
    "\n",
    "## Pourquoi cette √©tape dans notre progression ?\n",
    "\n",
    "Apr√®s avoir √©tabli une baseline **BM25** (requ√™te brute), puis test√© :\n",
    "- l'**enrichissement de requ√™te** (query understanding) c√¥t√© BM25,\n",
    "- et le **filtrage m√©tier** du corpus,\n",
    "\n",
    "on passe ici √† l‚Äô√©tape suivante : **remplacer le retriever lexical par un retriever s√©mantique**, tout en **conservant l‚Äôenrichissement m√©tier**.\n",
    "\n",
    "L‚Äôid√©e est de tester l‚Äôhypoth√®se suivante :\n",
    "\n",
    "> Quand la requ√™te utilisateur est ambigu√´ ou ‚Äúnon juridique‚Äù dans sa formulation,  \n",
    "> l‚Äôenrichissement m√©tier fournit des concepts stables, et le dense retrieval peut alors exploiter la similarit√© s√©mantique pour mieux retrouver les bons passages.\n",
    "\n",
    "‚úÖ Protocole strict (comparabilit√©) :\n",
    "- m√™me corpus `documents` (filtr√© ‚ÄúCode du travail‚Äù),\n",
    "- m√™mes questions (`benchmark_queries`),\n",
    "- m√™mes m√©triques (Recall@10, MRR, nDCG@10),\n",
    "- **seul le retriever change** (BM25 ‚Üí dense embeddings) et on conserve la couche ‚Äúm√©tier‚Äù.\n",
    "\n",
    "---\n",
    "## üß† Embedder utilis√© (Dense Retrieval)\n",
    "\n",
    "Dans ce stage, le retrieval dense repose sur l‚Äôembedder :\n",
    "\n",
    "- **Embedder (Sentence-Transformers)** : `all-MiniLM-L6-v2` *(384 dimensions, rapide, baseline robuste)*\n",
    "\n",
    "### üìå M√©mo important (alignement projet)\n",
    "Pour √©viter tout biais et garantir une vraie coh√©rence ‚Äúretrieval ‚Üí g√©n√©ration‚Äù, il est indispensable de se synchroniser avec le d√©veloppeur du chatbot LLM afin de :\n",
    "\n",
    "- **valider l‚Äôembedder cible** qui sera utilis√© en production (retrieval, indexation, √©ventuellement reranking),\n",
    "- s‚Äôassurer que **l‚Äôindex** et les requ√™tes sont encod√©s avec **le m√™me mod√®le** (sinon d√©gradation forte de la similarit√©),\n",
    "- arbitrer entre :\n",
    "  - performance s√©mantique,\n",
    "  - co√ªt CPU/GPU,\n",
    "  - latence,\n",
    "  - stabilit√© multilingue,\n",
    "  - compatibilit√© avec le domaine juridique.\n",
    "\n",
    "üëâ Le choix final de l‚Äôembedder doit √™tre **d√©cid√© au niveau architecture**, car il conditionne directement la qualit√© du RAG et les performances globales du syst√®me.\n",
    "---\n",
    "\n",
    "## üîß Notes notebook\n",
    "\n",
    "- Si tu vois des erreurs `ModuleNotFoundError` (`corpus_loader`, `metrics`, `benchmark_queries`‚Ä¶), c‚Äôest juste que le notebook n‚Äôest pas lanc√© depuis la racine du projet : une cellule ci-dessous ajoute la racine au `sys.path`.\n",
    "- Le fichier `juridical_dictionary.yml` doit √™tre accessible depuis le r√©pertoire courant (ou adapte le chemin dans la cellule d√©di√©e).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc2f21",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup (d√©pendances)\n",
    "\n",
    "Si besoin, installe les d√©pendances utilis√©es dans ce notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd2a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installation des d√©pendances n√©cessaires (√† ex√©cuter une seule fois par environnement)\n",
    "%pip -q install sentence-transformers scikit-learn ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13c5caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = d:\\-- Projet RAG Avocats --\\codes_python\\notebooks\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "# On tente de se placer √† la racine du projet pour rendre les imports locaux disponibles.\n",
    "# Ajuste si ton notebook est dans un sous-dossier (ex: notebooks/ -> parent).\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Exemple : si ce notebook est dans un dossier \"notebooks\", d√©commente :\n",
    "# PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b98191",
   "metadata": {},
   "source": [
    "## üìö Dictionnaire m√©tier\n",
    "\n",
    "Le script charge `juridical_dictionary.yml`.  \n",
    "V√©rifie que ce fichier est pr√©sent dans le dossier courant (ou adapte le chemin ci-dessous).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01776aac",
   "metadata": {},
   "source": [
    "## üß™ Code (repris du script, identique hors adaptations notebook possibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f935fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus brut charg√© : 4422 documents\n",
      "Corpus filtr√© 'Code du travail' : 882 documents\n",
      "WARNING:tensorflow:From d:\\-- ML-Pro Formation 2025 --\\ML-Pro-venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22d6ff8ff344969856fac97cac94118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dense retrieval + requ√™te enrichie ===\n",
      "{'Recall@10': 0.6666666666666666, 'MRR': 0.38095238095238093, 'nDCG@10': 0.4035162162237942}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "STAGE 9 ‚Äì DENSE RETRIEVAL + QUERY UNDERSTANDING\n",
    "\"\"\"\n",
    "\n",
    "from corpus_loader import documents\n",
    "from query_understanding import process_user_query, load_juridical_dictionary\n",
    "from benchmark_queries import benchmark_queries\n",
    "from metrics import recall_at_k, reciprocal_rank, ndcg_at_k\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0. CHARGEMENT DU DICO DE juridical_dictionary.yml\n",
    "# =========================================================\n",
    "dictionary = load_juridical_dictionary(\"juridical_dictionary.yml\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. EMBEDDINGS\n",
    "# =========================================================\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "doc_texts = [doc[\"text\"] for doc in documents]\n",
    "doc_embeddings = model.encode(\n",
    "    doc_texts,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "\n",
    "def dense_search(query, k=10):\n",
    "    query_embedding = model.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "    scores = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "\n",
    "    ranked = sorted(\n",
    "        zip(documents, scores),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked[:k]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. BENCHMARK\n",
    "# =========================================================\n",
    "\n",
    "def evaluate():\n",
    "    recall_scores, mrr_scores, ndcg_scores = [], [], []\n",
    "\n",
    "    for q in benchmark_queries:\n",
    "        enriched = process_user_query(q[\"question\"], dictionary)\n",
    "        query = enriched[\"enriched_query\"]\n",
    "\n",
    "        results = dense_search(query, k=10)\n",
    "\n",
    "        recall_scores.append(recall_at_k(results, q[\"relevant_keywords\"], 10))\n",
    "        mrr_scores.append(reciprocal_rank(results, q[\"relevant_keywords\"]))\n",
    "        ndcg_scores.append(ndcg_at_k(results, q[\"relevant_keywords\"], 10))\n",
    "\n",
    "    return {\n",
    "        \"Recall@10\": sum(recall_scores) / len(recall_scores),\n",
    "        \"MRR\": sum(mrr_scores) / len(mrr_scores),\n",
    "        \"nDCG@10\": sum(ndcg_scores) / len(ndcg_scores),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== Dense retrieval + requ√™te enrichie ===\")\n",
    "    print(evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b567b",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion (issue du script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e2eb0",
   "metadata": {},
   "source": [
    "## Conclusion ‚Äì Enseignements du benchmark RAG juridique\n",
    "\n",
    "Ce benchmark avait pour objectif d‚Äô√©valuer l‚Äôimpact r√©el de diff√©rentes briques\n",
    "(Retrieval lexical, filtrage m√©tier, compr√©hension de requ√™te, retrieval s√©mantique)\n",
    "sur un cas d‚Äôusage juridique simple mais repr√©sentatif.\n",
    "\n",
    "Le protocole exp√©rimental est volontairement strict :\n",
    "- m√™me corpus,\n",
    "- m√™mes questions,\n",
    "- m√™mes m√©triques,\n",
    "- seule la brique test√©e varie.\n",
    "\n",
    "---\n",
    "\n",
    "### R√©sum√© des r√©sultats\n",
    "\n",
    "| Configuration                         | Recall@10 | MRR   | nDCG@10 |\n",
    "|---------------------------------------|-----------|-------|---------|\n",
    "| BM25 ‚Äì requ√™te brute                  | 0.33      | 0.33  | 0.33 |\n",
    "| BM25 ‚Äì requ√™te enrichie m√©tier        | 0.33      | 0.33  | 0.33 | script 5.\n",
    "| BM25 filtr√© + requ√™te enrichie        | 0.33      | 0.33  | 0.33 | script 6.\n",
    "| Dense retrieval + requ√™te enrichie    | 0.67      |0.38   | 0.40 | script 7.\n",
    "\n",
    "---\n",
    "\n",
    "### Lecture des r√©sultats\n",
    "\n",
    "1. **BM25 constitue une baseline solide en contexte juridique**  \n",
    "   Les r√©sultats montrent que le BM25 est d√©j√† performant pour des requ√™tes\n",
    "   fortement lexicalis√©es (articles, notions juridiques explicites).\n",
    "   L‚Äôenrichissement de la requ√™te n‚Äôam√©liore pas les m√©triques, ce qui est attendu :\n",
    "   le moteur lexical disposait d√©j√† des bons termes discriminants.\n",
    "\n",
    "2. **Le filtrage m√©tier seul n‚Äôest pas suffisant pour am√©liorer la pertinence**  \n",
    "   R√©duire le p√©rim√®tre documentaire diminue le bruit, mais ne corrige pas\n",
    "   le d√©calage entre langage utilisateur et langage juridique.\n",
    "   Les faux n√©gatifs critiques persistent.\n",
    "\n",
    "3. **La compr√©hension m√©tier devient d√©cisive pour le retrieval s√©mantique**  \n",
    "   L‚Äôintroduction d‚Äôun dictionnaire juridique explicite permet de normaliser\n",
    "   l‚Äôintention utilisateur et d‚Äôenrichir la requ√™te avec des concepts juridiques pertinents.\n",
    "   Cette structuration du langage est le facteur cl√© qui permet au retrieval dense\n",
    "   d‚Äôexprimer son potentiel.\n",
    "\n",
    "4. **Le gain observ√© sur le dense retrieval est significatif et mesurable**  \n",
    "   Le rappel est doubl√© (0.33 ‚Üí 0.67) et le ranking s‚Äôam√©liore.\n",
    "   Ce gain ne provient pas du mod√®le seul, mais de l‚Äôassociation\n",
    "   entre compr√©hension m√©tier et similarit√© s√©mantique.\n",
    "\n",
    "---\n",
    "\n",
    "### Enseignement cl√©\n",
    "\n",
    "> En RAG juridique, la performance ne vient pas d‚Äôun changement de mod√®le,\n",
    "> mais de la structuration explicite du langage m√©tier.\n",
    "> Les algorithmes amplifient un signal correctement pos√© ;\n",
    "> ils ne compensent pas une compr√©hension absente.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications pour un syst√®me RAG en production\n",
    "\n",
    "- Le BM25 reste un excellent garde-fou lexical.\n",
    "- Le retrieval dense ne doit pas √™tre utilis√© seul.\n",
    "- Une couche explicite de *query understanding* m√©tier est indispensable.\n",
    "- Les am√©liorations doivent √™tre pilot√©es par des m√©triques mesurables,\n",
    "  et non par intuition ou effet de mode.\n",
    "\n",
    "Ce benchmark fournit ainsi une base saine, mesurable et am√©liorable\n",
    "pour la construction d‚Äôun moteur RAG juridique fiable et contr√¥l√©."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML-Pro-venv)",
   "language": "python",
   "name": "ml-pro-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
