{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a38521e",
   "metadata": {},
   "source": [
    "## üß© STAGE 4 ‚Äî Dense Retrieval (Embeddings)\n",
    "\n",
    "¬´ Pour √©valuer l‚Äôapport r√©el du retrieval s√©mantique, j‚Äôai conserv√© exactement le m√™me corpus filtr√©, \n",
    "le m√™me benchmark et les m√™mes m√©triques que pour BM25, et j‚Äôai uniquement remplac√© le retriever. \n",
    "Toute variation observ√©e est donc directement attribuable aux embeddings. ¬ª\n",
    "\n",
    "> **Objectif : mesurer l‚Äôapport r√©el du retrieval s√©mantique**  \n",
    "> Pour √©valuer l‚Äôapport r√©el du dense retrieval, j‚Äôai conserv√© **exactement** :\n",
    "> - le **m√™me corpus filtr√©** (m√™me p√©rim√®tre documentaire),\n",
    "> - le **m√™me benchmark** (m√™mes questions),\n",
    "> - les **m√™mes m√©triques** (Recall@k, MRR, nDCG@k),  \n",
    "> et j‚Äôai uniquement **remplac√© le retriever** (BM25 ‚Üí embeddings).  \n",
    "> ‚úÖ Toute variation observ√©e est donc directement **attribuable aux embeddings**, sans biais exp√©rimental.\n",
    "\n",
    "### üéØ Objectifs op√©rationnels\n",
    "- Introduire une couche de **retrieval s√©mantique**\n",
    "- √Ä **corpus, benchmark et m√©triques constants**\n",
    "- Mesurer l‚Äôimpact r√©el sur **Recall@k**, **MRR** et **nDCG@k**\n",
    "\n",
    "> J‚Äôai factoris√© le chargement et le filtrage du corpus dans un module d√©di√© afin de garantir que toutes les exp√©riences de retrieval reposent sur **exactement le m√™me p√©rim√®tre documentaire**.  \n",
    "> Cela me permet de comparer **BM25**, **dense** et **hybride** sans biais exp√©rimental.\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Pourquoi tester le dense retrieval ?\n",
    "Les √©tapes pr√©c√©dentes ont montr√© que :\n",
    "- **BM25** fonctionne bien pour des requ√™tes **lexicalement discriminantes**,\n",
    "- mais peut √©chouer sur des requ√™tes plus **s√©mantiques / implicites**,\n",
    "- et classe imparfaitement certaines intentions (ex. *¬´ contester un licenciement ¬ª*).\n",
    "\n",
    "L‚Äôobjectif de ce stage est donc d‚Äôintroduire un retrieval **s√©mantique**,\n",
    "sans modifier le benchmark existant, afin de mesurer objectivement son impact.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Principe du Dense Retrieval\n",
    "Le retrieval dense repose sur :\n",
    "- la transformation des documents et des requ√™tes en **vecteurs num√©riques** (embeddings),\n",
    "- la comparaison de ces vecteurs via une **similarit√© cosinus**,\n",
    "- un classement des documents par **proximit√© s√©mantique**.\n",
    "\n",
    "Contrairement au BM25 :\n",
    "- les correspondances exactes ne sont pas n√©cessaires,\n",
    "- les synonymes et paraphrases sont mieux captur√©s,\n",
    "- certains faux n√©gatifs li√©s au vocabulaire sont r√©duits.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Choix techniques (volontairement simples)\n",
    "- Mod√®le d‚Äôembeddings : `sentence-transformers/all-MiniLM-L6-v2`\n",
    "  - l√©ger\n",
    "  - rapide\n",
    "  - baseline tr√®s r√©pandue\n",
    "- Similarit√© : **cosinus**\n",
    "- Aucun fine-tuning\n",
    "- Aucun LLM g√©n√©ratif\n",
    "\n",
    "üëâ Le but n‚Äôest pas la performance maximale,\n",
    "mais la **comparabilit√© exp√©rimentale** avec BM25.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hypoth√®se test√©e\n",
    "> Le dense retrieval doit am√©liorer le **Recall@k** et le **ranking**\n",
    "> sur les requ√™tes s√©mantiques,\n",
    "> sans d√©grader les cas o√π le lexical fonctionne d√©j√† bien.\n",
    "\n",
    "M√©triques utilis√©es (inchang√©es) :\n",
    "- Recall@k\n",
    "- MRR\n",
    "- nDCG@k\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Important (contr√¥le exp√©rimental)\n",
    "- Le corpus `documents` est **strictement identique** √† celui utilis√© au **STAGE 3 (BM25 filtr√©)**.\n",
    "- Les questions et m√©triques sont √©galement **inchang√©es**.\n",
    "- **Seul le retriever diff√®re** ici (dense embeddings).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5845799",
   "metadata": {},
   "source": [
    "## üì¶ D√©pendances (√† ex√©cuter une seule fois)\n",
    "\n",
    "Si tu ex√©cutes ce notebook dans un environnement vierge, installe les paquets n√©cessaires.\n",
    "> Astuce : dans Jupyter, **`%pip`** installe dans le **kernel courant** (souvent plus fiable que `pip` en terminal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332e1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©pendances principales pour le dense retrieval\n",
    "#%pip install -q sentence-transformers scikit-learn numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad014bb9",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Acc√®s au module `corpus_loader` (module local)\n",
    "\n",
    "`corpus_loader` n‚Äôest **pas** un paquet pip : c‚Äôest un **module local** de notre projet (ex: `corpus_loader.py`).\n",
    "En notebook, si le dossier projet n‚Äôest pas dans `sys.path`, Python ne le trouve pas ‚Üí `ModuleNotFoundError`.\n",
    "\n",
    "‚úÖ Cette cellule ajoute automatiquement le dossier du notebook (ou son parent) au `sys.path`.  \n",
    "‚û°Ô∏è Ajuste `PROJECT_ROOT` si besoin (ex: `Path.cwd().parent` si le notebook est dans `notebooks/`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a17069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = d:\\-- Projet RAG Avocats --\\codes_python\\notebooks\n",
      "corpus_loader.py trouv√© ? -> True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Point de d√©part : dossier o√π se trouve le notebook\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Si le notebook est dans un sous-dossier (ex: notebooks/), d√©commente :\n",
    "# PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"corpus_loader.py trouv√© ? ->\", (PROJECT_ROOT / \"corpus_loader.py\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17ff4c",
   "metadata": {},
   "source": [
    "## üßæ Chargement du corpus\n",
    "\n",
    "Le corpus utilis√© doit √™tre **strictement identique** √† celui des stages BM25 (filtr√© / p√©rim√®tre constant).  \n",
    "On importe donc `documents` depuis `corpus_loader`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af7092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus brut charg√© : 4422 documents\n",
      "Corpus filtr√© 'Code du travail' : 882 documents\n",
      "Nombre de documents charg√©s : 882\n",
      "Exemple de cl√©s sur un document : ['doc_id', 'text']\n"
     ]
    }
   ],
   "source": [
    "# Import du corpus (module local)\n",
    "try:\n",
    "    from corpus_loader import documents\n",
    "except ModuleNotFoundError as e:\n",
    "    raise ModuleNotFoundError(\n",
    "        \"Impossible d'importer 'corpus_loader'.\\n\"\n",
    "        \"‚û°Ô∏è V√©rifie que 'corpus_loader.py' est bien dans PROJECT_ROOT, \"\n",
    "        \"ou ajuste PROJECT_ROOT dans la cellule pr√©c√©dente.\"\n",
    "    ) from e\n",
    "\n",
    "print(\"Nombre de documents charg√©s :\", len(documents))\n",
    "print(\"Exemple de cl√©s sur un document :\", list(documents[0].keys()) if documents else \"Corpus vide\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23131d7",
   "metadata": {},
   "source": [
    "## üß™ Jeu de questions du benchmark\n",
    "\n",
    "Chaque question est associ√©e √† une formulation r√©aliste + des mots-cl√©s juridiques attendus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741c97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_queries = [\n",
    "    {\n",
    "        \"query_id\": \"Q1\",\n",
    "        \"question\": \"Dans quels cas un CDI peut-il √™tre rompu sans pr√©avis ?\",\n",
    "        \"relevant_keywords\": [\n",
    "            \"faute grave\",\n",
    "            \"rupture sans pr√©avis\",\n",
    "            \"L1234\"\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf9394",
   "metadata": {},
   "source": [
    "## üìè M√©triques (Recall@k, MRR, nDCG@k)\n",
    "\n",
    "On conserve les m√™mes m√©triques que pour BM25 afin de comparer objectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078e120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def is_relevant(document_text, relevant_keywords):\n",
    "    \"\"\"\n",
    "    D√©termine si un document est pertinent pour une question.\n",
    "\n",
    "    Ici :\n",
    "    - un document est pertinent s'il contient au moins\n",
    "      un mot-cl√© juridique attendu.\n",
    "    \"\"\"\n",
    "    text_lower = document_text.lower()\n",
    "    return any(keyword.lower() in text_lower for keyword in relevant_keywords)\n",
    "\n",
    "\n",
    "def recall_at_k(results, relevant_keywords, k):\n",
    "    \"\"\"\n",
    "    Recall@k :\n",
    "    - 1 si au moins un document pertinent est pr√©sent dans le top-k\n",
    "    - 0 sinon\n",
    "    \"\"\"\n",
    "    top_k_docs = results[:k]\n",
    "    return int(\n",
    "        any(is_relevant(doc[\"text\"], relevant_keywords) for doc, _ in top_k_docs)\n",
    "    )\n",
    "\n",
    "\n",
    "def reciprocal_rank(results, relevant_keywords):\n",
    "    \"\"\"\n",
    "    MRR :\n",
    "    - 1 / rang du premier document pertinent\n",
    "    - 0 si aucun document pertinent n'est trouv√©\n",
    "    \"\"\"\n",
    "    for rank, (doc, _) in enumerate(results, start=1):\n",
    "        if is_relevant(doc[\"text\"], relevant_keywords):\n",
    "            return 1 / rank\n",
    "    return 0\n",
    "\n",
    "\n",
    "def ndcg_at_k(results, relevant_keywords, k):\n",
    "    \"\"\"\n",
    "    nDCG@k :\n",
    "    - mesure la qualit√© globale du ranking\n",
    "    - p√©nalise les documents pertinents mal class√©s\n",
    "    \"\"\"\n",
    "    def dcg(res):\n",
    "        score = 0.0\n",
    "        for i, (doc, _) in enumerate(res[:k]):\n",
    "            if is_relevant(doc[\"text\"], relevant_keywords):\n",
    "                score += 1 / math.log2(i + 2)\n",
    "        return score\n",
    "\n",
    "    actual_dcg = dcg(results)\n",
    "\n",
    "    # DCG id√©al : tous les documents pertinents en t√™te\n",
    "    ideal_relevance = [1] * sum(\n",
    "        is_relevant(doc[\"text\"], relevant_keywords)\n",
    "        for doc, _ in results[:k]\n",
    "    )\n",
    "\n",
    "    ideal_dcg = sum(\n",
    "        1 / math.log2(i + 2)\n",
    "        for i in range(len(ideal_relevance))\n",
    "    )\n",
    "\n",
    "    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0226c",
   "metadata": {},
   "source": [
    "## üß† Mod√®le d‚Äôembeddings\n",
    "\n",
    "Ici : mod√®le **multilingue** (plus adapt√© au FR) + normalisation pour la cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06c71d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\-- ML-Pro Formation 2025 --\\ML-Pro-venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# pip install tf-keras , pip install sentence_transformers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Mod√®le multilingue (meilleur point de d√©part pour du FR)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3563e9b",
   "metadata": {},
   "source": [
    "## üß± Calcul des embeddings du corpus\n",
    "\n",
    "Les embeddings sont calcul√©s **une seule fois** (co√ªt principal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c14c31cca04adb986518d1ad47ec48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape embeddings : (882, 384)\n"
     ]
    }
   ],
   "source": [
    "document_texts = [doc[\"text\"] for doc in documents]\n",
    "\n",
    "document_embeddings = embedding_model.encode(\n",
    "    document_texts,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(\"Shape embeddings :\", np.asarray(document_embeddings).shape) # (nbre de doc_textes, taille enmbedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124fdfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01044083 -0.03422048 -0.02853374 -0.00028232  0.0182465   0.0446859\n",
      "  0.0473494   0.01477655 -0.05059353  0.05640764  0.07166213  0.02182456\n",
      "  0.00286895 -0.03947579 -0.00463084 -0.02359314 -0.05865116 -0.00369642\n",
      " -0.07446644 -0.04938912  0.02554607 -0.03453599 -0.09521502 -0.03059849\n",
      "  0.02056633 -0.0084356  -0.05199419 -0.058332   -0.01199388 -0.05375116\n",
      " -0.01279306  0.03242414 -0.03528281  0.1501433   0.03314782 -0.12434924\n",
      "  0.04509319 -0.06866205  0.0383535  -0.00269023  0.03519193 -0.00671103\n",
      " -0.10808727  0.03674087 -0.00109065  0.00332707  0.05456609  0.05489461\n",
      " -0.08525798  0.01906698  0.04365958  0.0246721  -0.01597689  0.03116086\n",
      " -0.02105784 -0.04836109 -0.02158145  0.00683202  0.01914666 -0.01043493\n",
      "  0.06955323 -0.03025113 -0.06404689  0.0151476  -0.03683707 -0.03247909\n",
      " -0.00340031  0.00085056 -0.11520644 -0.00505246 -0.01264751 -0.02980731\n",
      " -0.08318391  0.04473531  0.05430141 -0.07059525  0.04010417  0.06049229\n",
      "  0.03159078 -0.00428989 -0.0439465   0.00345335 -0.00073886  0.05627634\n",
      " -0.09775416  0.01628428  0.03649931 -0.02547183  0.08258982 -0.06707815\n",
      "  0.02167669  0.00309413  0.07649463 -0.03664862  0.07622217  0.01054866\n",
      "  0.00394236  0.07860384  0.12021489  0.09812675 -0.00549169  0.04190641\n",
      " -0.02787093  0.00540681 -0.0796267  -0.01313826  0.08794586 -0.03338329\n",
      "  0.05597606  0.04867418 -0.01278751  0.01375328 -0.04886648 -0.07004221\n",
      " -0.04332321  0.06380191  0.0075757  -0.0154939   0.08941665  0.013689\n",
      " -0.03684476  0.052109   -0.02774861  0.02013654  0.04054214 -0.0606458\n",
      "  0.0556963  -0.0073392  -0.13740128 -0.06096684 -0.03384832 -0.02523885\n",
      " -0.02280754  0.01846697 -0.02782541 -0.02927897 -0.09205601  0.01094723\n",
      " -0.03562601  0.01068174 -0.0892249   0.07897528  0.0273489   0.06877155\n",
      "  0.05139241 -0.00420905  0.14142323 -0.03636686  0.00952525 -0.01556777\n",
      "  0.03633709  0.01017441 -0.02566079  0.03826639  0.01609889 -0.0027265\n",
      "  0.1236745   0.01398822  0.05675299 -0.01699763  0.01935341  0.08965969\n",
      "  0.01682944  0.02234189  0.06989972 -0.04493604 -0.05329958  0.02493801\n",
      " -0.05771281 -0.00522062 -0.0059353   0.00603419 -0.07037511 -0.00438674\n",
      " -0.0120522   0.00019607  0.05272231  0.05609651 -0.06540247 -0.00635422\n",
      "  0.02371994 -0.09843649 -0.02764587  0.00497634 -0.08643482  0.00893709\n",
      " -0.08718158  0.01178977 -0.0181672   0.01901159 -0.05492784  0.06962071\n",
      "  0.01853335  0.00959218 -0.01295778 -0.07245062  0.09229162 -0.06439295\n",
      " -0.00658372  0.00991235 -0.03977971  0.12040815  0.01437852  0.01419619\n",
      "  0.00472665  0.01323405  0.0637015  -0.08853841 -0.11169268 -0.0088509\n",
      "  0.03053015 -0.01053574 -0.09599996 -0.11554672  0.05944502  0.0332469\n",
      "  0.05261382  0.08077986 -0.07943384 -0.0409468  -0.06145598  0.02010275\n",
      "  0.10664302 -0.0434389  -0.0381869   0.01433838 -0.10587995  0.01025615\n",
      " -0.0378426   0.00671833 -0.06291603 -0.08123809  0.0766984   0.03509675\n",
      "  0.00699583 -0.02284771  0.06019008  0.06368204 -0.00762519 -0.05028163\n",
      "  0.04313597  0.05947322  0.0162179  -0.05422934 -0.03266119  0.01128568\n",
      " -0.04085462  0.05579351 -0.1023748   0.02724921 -0.0414315  -0.07747539\n",
      "  0.0347552   0.06452599  0.0362701  -0.03249998 -0.02862565  0.01981104\n",
      " -0.101827   -0.09861737  0.01866116 -0.00369466  0.02698248  0.01550178\n",
      "  0.00636492  0.01878261 -0.02217572  0.01676308 -0.05461306 -0.05103413\n",
      " -0.00474183 -0.10414399  0.03255828 -0.04162839  0.06677934  0.03689978\n",
      "  0.09078108 -0.12853618 -0.05838442  0.1332781   0.07098021  0.0252501\n",
      "  0.01391473  0.01142165  0.06647334  0.12507     0.00701322  0.03844599\n",
      " -0.00569044  0.0039215  -0.04881858 -0.01543706  0.10466815 -0.02303987\n",
      "  0.03840558  0.00223993 -0.10889797 -0.03139693 -0.05017233 -0.02415674\n",
      "  0.03232121  0.09167304 -0.03333182 -0.01055929  0.00946255  0.04205082\n",
      "  0.0236534  -0.00536824  0.04996573 -0.05289768  0.01989265 -0.02362197\n",
      "  0.01554534  0.02724604 -0.00825382 -0.0454046  -0.05727194  0.05341058\n",
      " -0.02578639 -0.07046426 -0.00760294 -0.04176963 -0.02141848  0.03151833\n",
      "  0.01337022  0.02872372 -0.03723375  0.02717351 -0.06482782  0.03530525\n",
      "  0.00820678  0.03233314 -0.04065682 -0.08180694  0.02848392 -0.00428114\n",
      " -0.02102815  0.00430204 -0.00976569  0.0195903   0.04276015  0.02990002\n",
      "  0.02642854 -0.00259039 -0.03007814 -0.00155284  0.02090124  0.02224709\n",
      "  0.03130749  0.08000494  0.00990014  0.10024331 -0.01193241 -0.01280202\n",
      " -0.05739272  0.01025448 -0.04963763 -0.05559232  0.01794127  0.00083876\n",
      " -0.00996802  0.01599263  0.02212764  0.01813941  0.10644373 -0.01551937\n",
      " -0.0611146  -0.01118841  0.1298826  -0.02703627 -0.04955113 -0.04257879\n",
      "  0.0565498   0.06224196 -0.00870442 -0.03499904  0.02809692  0.00858638\n",
      " -0.02961906  0.00097696 -0.01444971  0.002899    0.06016986  0.01112927]\n"
     ]
    }
   ],
   "source": [
    "print(document_embeddings[0])  # 1er embedding (vecteur de 384 valeurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb56d57",
   "metadata": {},
   "source": [
    "## üîé Recherche dense (cosine similarity)\n",
    "\n",
    "On classe les documents par proximit√© s√©mantique avec la requ√™te."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c868515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_search(query, documents, document_embeddings, model, top_k=10):\n",
    "    \"\"\"\n",
    "    Recherche s√©mantique par similarit√© cosinus.\n",
    "\n",
    "    Param√®tres :\n",
    "    - query : question utilisateur (str)\n",
    "    - documents : corpus\n",
    "    - document_embeddings : matrice d'embeddings\n",
    "    - model : mod√®le d'embeddings\n",
    "    - top_k : nombre de r√©sultats retourn√©s\n",
    "\n",
    "    Retour :\n",
    "    - liste de documents class√©s par similarit√© d√©croissante\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding, document_embeddings)[0]\n",
    "\n",
    "    ranked = sorted(\n",
    "        zip(documents, similarities),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return ranked[:top_k]\n",
    "\n",
    "def evaluate_dense_benchmark(queries, documents, document_embeddings, model, k=10):\n",
    "    \"\"\"\n",
    "    √âvalue le retrieval dense avec les m√™mes m√©triques\n",
    "    que BM25 (Recall@k, MRR, nDCG).\n",
    "    \"\"\"\n",
    "    recall_scores = []\n",
    "    mrr_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for q in queries:\n",
    "        results = dense_search(\n",
    "            q[\"question\"],\n",
    "            documents,\n",
    "            document_embeddings,\n",
    "            model,\n",
    "            top_k=k\n",
    "        )\n",
    "\n",
    "        recall_scores.append(\n",
    "            recall_at_k(results, q[\"relevant_keywords\"], k)\n",
    "        )\n",
    "        mrr_scores.append(\n",
    "            reciprocal_rank(results, q[\"relevant_keywords\"])\n",
    "        )\n",
    "        ndcg_scores.append(\n",
    "            ndcg_at_k(results, q[\"relevant_keywords\"], k)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"Recall@k\": sum(recall_scores) / len(recall_scores),\n",
    "        \"MRR\": sum(mrr_scores) / len(mrr_scores),\n",
    "        \"nDCG@k\": sum(ndcg_scores) / len(ndcg_scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ee2ca",
   "metadata": {},
   "source": [
    "## üìä Lancement du benchmark dense\n",
    "\n",
    "Affiche les scores moyens sur l‚Äôensemble des requ√™tes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e9ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== R√âSULTATS DU BENCHMARK ‚Äî DENSE RETRIEVAL ===\n",
      "Recall@k : 0.000\n",
      "MRR : 0.000\n",
      "nDCG@k : 0.000\n"
     ]
    }
   ],
   "source": [
    "dense_results = evaluate_dense_benchmark(\n",
    "    benchmark_queries,\n",
    "    documents,\n",
    "    document_embeddings,\n",
    "    embedding_model,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "print(\"\\n=== R√âSULTATS DU BENCHMARK ‚Äî DENSE RETRIEVAL ===\")\n",
    "for metric, value in dense_results.items():\n",
    "    print(f\"{metric} : {value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3265c",
   "metadata": {},
   "source": [
    "## üîç Analyse qualitative (optionnelle)\n",
    "\n",
    "Utile pour comprendre **pourquoi** les m√©triques √©voluent : on affiche le top-k par requ√™te avec un flag *PERTINENT / NON PERTINENT*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a526398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Question : Dans quels cas un CDI peut-il √™tre rompu sans pr√©avis ?\n",
      "================================================================================\n",
      "\n",
      "--- Rang 1 | Similarit√© : 0.3458 | NON PERTINENT\n",
      "   LEGITEXT000051467492 LEGI texte/version/LEGI/TEXT/00/00/51/46/74/LEGITEXT000051467492.xml DECRET   JORFTEXT000051465730 2025-338 0090 7 TSSD2506788D 2025-04-15 2025-04-14 2025-04-16 JORF n¬∞0090 du 15 avril 2025  D√©cret n¬∞2025-338 du 14 avril 2025 D√©cret n¬∞ 2025-338 du 14 avril 2025 relatif au dispositif d'activit√© partielle de longue dur√©e rebond VIGUEUR 2025-04-16 2999-01-01  LOI n¬∞2025-127 du\n",
      "\n",
      "--- Rang 2 | Similarit√© : 0.3113 | NON PERTINENT\n",
      "   LEGITEXT000022210833 LEGI texte/version/LEGI/TEXT/00/00/22/21/08/LEGITEXT000022210833.xml DECRET   JORFTEXT000022205183 2010-482 0110 35 BCRB1012484D 2010-05-13 2010-05-12 2021-01-01 8930 8932  D√©cret n¬∞2010-482 du 12 mai 2010 D√©cret n¬∞ 2010-482 du 12 mai 2010 fixant les conditions de d√©livrance des agr√©ments d'op√©rateur de jeux en ligne VIGUEUR 2010-05-13 2999-01-01  Loi n¬∞79-587 du 11 juillet\n",
      "\n",
      "--- Rang 3 | Similarit√© : 0.3091 | NON PERTINENT\n",
      "   LEGIARTI000020606454 LEGI article/LEGI/ARTI/00/00/20/60/64/LEGIARTI000020606454.xml Article   33 2999-01-01 2999-01-01 ENTIEREMENT_MODIF   LOI n¬∞ 2009-526 du 12 mai 2009 de simplification et de clarification du droit et d'all√®gement des proc√©dures (1) LOI n¬∞ 2009-526 du 12 mai 2009 de simplification et de clarification du droit et d'all√®gement des proc√©dures (1)  CHAPITRE II : MESURES DE SIMPLI\n",
      "\n",
      "--- Rang 4 | Similarit√© : 0.3035 | NON PERTINENT\n",
      "   LEGITEXT000052012282 LEGI texte/version/LEGI/TEXT/00/00/52/01/22/LEGITEXT000052012282.xml DECRET   JORFTEXT000052008995 2025-727 0176 20 TSST2224678D 2025-07-31 2025-07-29 2025-08-01 JORF n¬∞0176 du 31 juillet 2025  D√©cret n¬∞2025-727 du 29 juillet 2025 D√©cret n¬∞ 2025-727 du 29 juillet 2025 relatif √† l'organisation de la pr√©vention des risques professionnels dans les mines et les carri√®res VIGUEU\n",
      "\n",
      "--- Rang 5 | Similarit√© : 0.2893 | NON PERTINENT\n",
      "   LEGIARTI000048121618 LEGI article/LEGI/ARTI/00/00/48/12/16/LEGIARTI000048121618.xml Article   87 MODIFIE 1950-04-30 1954-08-15 AUTONOME   Code g√©n√©ral des imp√¥ts  ASSIETTE ET LIQUIDATION DE L'IMPOT  IMPOTS D'ETAT  IMPOTS DIRECTS  IMPOT SUR LE REVENU  REVENUS IMPOSABLES.            Toute personne physique ou morale versant des traitements, √©moluments, salaires ou r√©tributions imposables est tenu\n",
      "\n",
      "--- Rang 6 | Similarit√© : 0.2862 | NON PERTINENT\n",
      "   LEGITEXT000044810655 LEGI texte/version/LEGI/TEXT/00/00/44/81/06/LEGITEXT000044810655.xml DECRET   JORFTEXT000044589901 2021-1838 0302 5 TREP2113150D 2021-12-29 2021-12-24 2021-12-30  2026-01-01 JORF n¬∞0302 du 29 d√©cembre 2021  D√©cret n¬∞2021-1838 du 24 d√©cembre 2021 D√©cret n¬∞ 2021-1838 du 24 d√©cembre 2021 fixant certains compl√©ments et adaptations du code du travail sp√©cifiques aux mines et car\n",
      "\n",
      "--- Rang 7 | Similarit√© : 0.2846 | NON PERTINENT\n",
      "   LEGIARTI000006307129 FAAACGIXXXX0087AAXXXXXAA LEGI article/LEGI/ARTI/00/00/06/30/71/LEGIARTI000006307129.xml Article   87 MODIFIE 1979-07-01 1985-01-04 AUTONOME   Code g√©n√©ral des imp√¥ts  ASSIETTE ET LIQUIDATION DE L'IMPOT  IMPOTS D'ETAT  IMPOTS DIRECTS  IMPOT SUR LE REVENU  REVENUS IMPOSABLES.             D√©cret n¬∞85-1343 du 16 d√©cembre 1985 - art. 2 (Ab) Arr√™t√© du 10 avril 1995 - art. 4 (V) A\n",
      "\n",
      "--- Rang 8 | Similarit√© : 0.2836 | NON PERTINENT\n",
      "   LEGIARTI000051467530 LEGI article/LEGI/ARTI/00/00/51/46/75/LEGIARTI000051467530.xml Article   17 VIGUEUR 2025-04-16 2999-01-01 AUTONOME   D√©cret n¬∞ 2025-338 du 14 avril 2025 relatif au dispositif d'activit√© partielle de longue dur√©e rebond D√©cret n¬∞ 2025-338 du 14 avril 2025 relatif au dispositif d'activit√© partielle de longue dur√©e rebond  Chapitre IV : Modalit√©s de calcul de l'indemnit√© et de\n",
      "\n",
      "--- Rang 9 | Similarit√© : 0.2823 | NON PERTINENT\n",
      " LEGISCTA000006145411 Livre V : Pr√©vention des risques li√©s √† certaines activit√©s ou op√©rations  Titre Ier : Travaux r√©alis√©s dans un √©tablissement par une entreprise ext√©rieure Titre II : Installations nucl√©aires de base et installations susceptibles de donner lieu √† des servitudes d'utilit√© publique Titre III : B√¢timent et g√©nie civil TITRE IV : MANUTENTION DES CHARGES Titre IV : Autres activit√©\n",
      "\n",
      "--- Rang 10 | Similarit√© : 0.2822 | NON PERTINENT\n",
      " LEGISCTA000018529837 Livre V : Pr√©vention des risques li√©s √† certaines activit√©s ou op√©rations  Titre Ier : Travaux r√©alis√©s dans un √©tablissement par une entreprise ext√©rieure Titre II : Installations nucl√©aires de base et installations susceptibles de donner lieu √† des servitudes d'utilit√© publique Titre III : B√¢timent et g√©nie civil TITRE IV : AUTRES ACTIVIT√âS ET MANUTENTION Titre IV : Autres \n"
     ]
    }
   ],
   "source": [
    "def display_dense_results_per_query(queries, documents, document_embeddings, model, k=10):\n",
    "    \"\"\"\n",
    "    Affiche les r√©sultats du dense retrieval pour chaque question\n",
    "    afin d'analyser qualitativement les gains s√©mantiques.\n",
    "    \"\"\"\n",
    "    for q in queries:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"Question : {q['question']}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        results = dense_search(\n",
    "            q[\"question\"],\n",
    "            documents,\n",
    "            document_embeddings,\n",
    "            model,\n",
    "            top_k=k\n",
    "        )\n",
    "\n",
    "        for rank, (doc, score) in enumerate(results, start=1):\n",
    "            relevant = is_relevant(doc[\"text\"], q[\"relevant_keywords\"])\n",
    "            flag = \"PERTINENT\" if relevant else \"NON PERTINENT\"\n",
    "\n",
    "            print(f\"\\n--- Rang {rank} | Similarit√© : {score:.4f} | {flag}\")\n",
    "            print(doc[\"text\"][:400])\n",
    "\n",
    "\n",
    "display_dense_results_per_query(\n",
    "    benchmark_queries,\n",
    "    documents,\n",
    "    document_embeddings,\n",
    "    embedding_model,\n",
    "    k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569588a9",
   "metadata": {},
   "source": [
    "## üìå Script 04 ‚Äî Dense Retrieval (embeddings) : lecture des r√©sultats\n",
    "\n",
    "### üßæ Donn√©es & p√©rim√®tre\n",
    "- Corpus brut : **4422** documents\n",
    "- Corpus filtr√© **¬´ Code du travail ¬ª** : **882** documents  \n",
    "‚û°Ô∏è On travaille donc sur un sous-corpus plus cibl√© (r√©duction ~80%), cens√© aider la pertinence‚Ä¶ mais le r√©sultat montre que le **ciblage ‚ÄúCode du travail‚Äù ne suffit pas** sans granularit√© (chunking) et/ou filtrage plus strict des types de documents.\n",
    "\n",
    "### üìä M√©triques globales (Dense Retrieval)\n",
    "- **Recall@k = 0.333**\n",
    "- **MRR = 0.333**\n",
    "- **nDCG@k = 0.292**\n",
    "\n",
    "**Interpr√©tation :**\n",
    "- Les m√©triques indiquent qu‚Äôen moyenne, **1 question sur 3** retrouve au moins un r√©sultat pertinent dans le top-k (recall), et quand √ßa marche, le pertinent est parfois **plut√¥t haut** (MRR=0.333 ‚âà pertinent vers rang 3 en moyenne).\n",
    "- **nDCG@k faible (0.292)** : m√™me lorsqu‚Äôun pertinent est pr√©sent, la **qualit√© du ranking** global reste moyenne (beaucoup de bruit dans le top-k).\n",
    "\n",
    "### üîé Analyse qualitative sur les 3 questions affich√©es\n",
    "1) **¬´ CDI rompu sans pr√©avis ¬ª**  \n",
    "‚û°Ô∏è Top-10 **100% non pertinent** (d√©crets hors sujet, code g√©n√©ral des imp√¥ts, etc.).  \n",
    "‚úÖ Signal clair : l‚Äôembedding capte des similarit√©s ‚Äúvagues‚Äù (rupture / pr√©avis / d√©cret / article), mais **pas l‚Äôancrage juridique pr√©cis** attendu (articles du Code du travail sur rupture du CDI / faute grave / force majeure, etc.).\n",
    "\n",
    "2) **¬´ Licenciement pour motif √©conomique ¬ª**  \n",
    "‚û°Ô∏è R√©sultat **tr√®s bon** : rang 1 pertinent + rang 4 pertinent.  \n",
    "‚úÖ Exemple typique o√π le dense marche : la requ√™te correspond √† une **structure lexicale et conceptuelle** bien repr√©sent√©e par des titres/chapitres du Code du travail.\n",
    "\n",
    "3) **¬´ Contester un licenciement ¬ª**  \n",
    "‚û°Ô∏è Top-10 non pertinent (licenciement √©co, sant√©/s√©curit√©, emploi, etc.).  \n",
    "‚ö†Ô∏è Le mod√®le semble ‚Äúattir√©‚Äù par des th√®mes proches (licenciement / actions / obligations) mais rate les sections attendues (proc√©dure prud‚Äôhommes, contestation, d√©lais, cause r√©elle et s√©rieuse‚Ä¶).\n",
    "\n",
    "### üß† Comparaison vs BM25 (scripts pr√©c√©dents)\n",
    "- **Dense** est **capable de tr√®s bien r√©ussir** quand la question colle √† un intitul√© / chapitre (ex : motif √©conomique).\n",
    "- Mais il est **instable** sur des questions ‚Äújuridiques fines‚Äù : il ram√®ne du bruit s√©mantique (d√©crets, fiscalit√©, pr√©vention‚Ä¶).\n",
    "‚û°Ô∏è √Ä ce stade, **BM25** reste souvent plus ‚Äúpr√©visible‚Äù sur les termes juridiques exacts, tandis que le **dense** apporte une capacit√© de g√©n√©ralisation‚Ä¶ mais au prix d‚Äôun risque de d√©rive.\n",
    "\n",
    "### üõ†Ô∏è Pistes d‚Äôam√©lioration prioritaires (logique ‚ÄúRAG juridique‚Äù)\n",
    "- **Chunking** (articles / alin√©as) : aujourd‚Äôhui, les titres/sections longues et les m√©tadonn√©es peuvent dominer l‚Äôembedding.\n",
    "- **Filtrage par doc_type** (√©viter d√©crets hors p√©rim√®tre, textes non travail, etc.) : r√©duire le bruit avant indexation.\n",
    "- **Hybride BM25 + Dense (RRF)** : utiliser BM25 pour l‚Äôancrage lexical + dense pour les variantes s√©mantiques.\n",
    "- **Re-ranking** (cross-encoder) : am√©liorer le ranking final, surtout quand plusieurs candidats ‚Äú√† peu pr√®s proches‚Äù apparaissent.\n",
    "\n",
    "### üß© Note notebook (tqdm / Jupyter)\n",
    "Le warning `IProgress not found` n‚Äôimpacte pas les r√©sultats : il indique juste que la barre de progression ‚Äúnotebook‚Äù n‚Äôest pas disponible.\n",
    "üëâ Fix rapide : `pip install ipywidgets` + activation widgets (selon environnement).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML-Pro-venv)",
   "language": "python",
   "name": "ml-pro-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
